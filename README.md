ğŸ§  Data Processing and Automation with Pandas (ETL & Pipeline)
ğŸ¯ Project Goal
The goal of this project is to help you learn how to use the Pandas library for data processing and to understand the basics of Docker and Apache Airflow.

You will use the EnergyZero API to get real energy price data for one week and build a full ETL (Extract â€“ Transform â€“ Load) pipeline.

ğŸ“¦ Project Steps
1ï¸âƒ£ Extract â€“ Get the Data
Use the EnergyZero API to get the last 7 days of energy price data.

Save the raw data as a JSON file on your computer.

2ï¸âƒ£ Transform â€“ Clean and Change the Data
Read the JSON file with Pandas and convert it into a DataFrame.

Split the column ReadingDate into two parts: Date and Time.

Add a new column called Price_with_VAT, which includes a 21% tax.

Check that column names, formats, and data types are correct.

3ï¸âƒ£ Load â€“ Save the Data
Save the transformed data in Parquet format in the folder data/processed/.

Parquet files are smaller and faster for data analysis.

ğŸ§° Tools You Will Use
ğŸ Python & Pandas â€“ to process and transform data
ğŸ³ Docker â€“ to run the project in a simple and portable environment
ğŸª¶ Apache Airflow â€“ to automate and schedule your ETL process
ğŸ”Œ EnergyZero API â€“ to get real-time energy price data

ğŸ“ What You Will Learn
After finishing this project, you will be able to:

âœ… Get data from a real API
âœ… Process and clean data using Pandas
âœ… Use Docker to containerize your project
âœ… Create and schedule workflows with Apache Airflow

ğŸ”— Useful Links
ğŸŒ EnergyZero API
"https://api.energyzero.nl/v1/energyprices?fromDate={start_date}
T00:00:00.000Z&tillDate={end_date}
T23:59:59.999Z&interval=4&usageType=1&inclBtw=false"


<img width="395" height="296" alt="Screenshot 2026-01-19 202641" src="https://github.com/user-attachments/assets/583bb2c8-677d-4e82-8e12-febb24e768f7" />



